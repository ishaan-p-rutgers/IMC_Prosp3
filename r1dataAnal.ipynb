{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar_params\n",
      "[-0.71823891 -0.50449378 -0.35583069 -0.22313214 -0.11187229]\n",
      "ma_params\n",
      "[-0.01331738 -0.0184114  -0.02800807 -0.03931557 -0.05538944]\n",
      "mean\n",
      "0.001116703890129671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "class ARIMA:\n",
    "    def __init__(self, p, d, q):\n",
    "        self.p = p # AR order\n",
    "        self.d = d # differencing order\n",
    "        self.q = q # MA order\n",
    "        self.ar_params = None # AR coefficients\n",
    "        self.ma_params = None # MA coefficients\n",
    "        self.mean = 0 # mean of differenced data\n",
    "    \n",
    "    def difference(self, data):\n",
    "        diff_data = data.copy()\n",
    "        for _ in range(self.d):\n",
    "            diff_data = np.diff(diff_data)\n",
    "        return diff_data\n",
    "\n",
    "    def inverse_difference(self, last_val, forecast):\n",
    "         for _ in range(self.d):\n",
    "            forecast = np.cumsum(np.insert(forecast, 0, last_val))\n",
    "            last_val = forecast[0]\n",
    "         return forecast\n",
    "\n",
    "    def train(self, data):\n",
    "        diff_data = self.difference(data)\n",
    "        self.mean = np.mean(diff_data)\n",
    "        diff_data_centered = diff_data - self.mean\n",
    "        if self.p > 0:\n",
    "            X_ar = [diff_data_centered[i-self.p:i][::-1] for i in range(self.p, len(diff_data_centered))]\n",
    "            y_ar = diff_data_centered[self.p:]\n",
    "            self.ar_params = np.linalg.solve(np.dot(np.transpose(X_ar), X_ar), np.dot(np.transpose(X_ar), y_ar))\n",
    "        else:\n",
    "            self.ar_params = np.array([])\n",
    "        if self.q > 0:\n",
    "            residuals = diff_data_centered[self.p:] - np.dot(X_ar, self.ar_params) if self.p > 0 else diff_data_centered\n",
    "            X_ma = [residuals[i-self.q:i][::-1] if i >= self.q else np.zeros(self.q) for i in range(len(residuals))]\n",
    "            y_ma = residuals\n",
    "            self.ma_params = np.linalg.solve(np.dot(np.transpose(X_ma), X_ma), np.dot(np.transpose(X_ma), y_ma))\n",
    "        else:\n",
    "            self.ma_params = np.array([])\n",
    "\n",
    "\n",
    "    def predict(self, data, steps):\n",
    "        diff_data = self.difference(data)\n",
    "        diff_data_centered = diff_data - self.mean\n",
    "        history_ar = list(diff_data_centered[-self.p:] if self.p > 0 else [])\n",
    "        history_ma = [0] * self.q if self.q > 0 else []\n",
    "        forecasts = []\n",
    "\n",
    "        for _ in range(steps - 1):\n",
    "            ar_pred = np.dot(history_ar, self.ar_params) if self.p > 0 else 0\n",
    "            ma_pred = np.dot(history_ma, self.ma_params) if self.q > 0 else 0\n",
    "            prediction = ar_pred + ma_pred + self.mean\n",
    "            forecasts.append(prediction)\n",
    "            history_ar.append(prediction)\n",
    "            if len(history_ar) > self.p:\n",
    "                history_ar.pop(0)\n",
    "            history_ma.append(diff_data_centered[-1] - ar_pred - ma_pred)\n",
    "            if len(history_ma) > self.q:\n",
    "                history_ma.pop(0)\n",
    "            diff_data_centered = np.append(diff_data_centered, prediction)\n",
    "\n",
    "        return self.inverse_difference(data[-1], np.array(forecasts))\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "plt.figure(figsize=(10, 5))\n",
    "p_df2 = pd.read_csv(\"prices_round_1_day_-2.csv\", sep=\";\")\n",
    "p_df1 = pd.read_csv(\"prices_round_1_day_-1.csv\", sep=\";\")\n",
    "p_df0 = pd.read_csv(\"prices_round_1_day_0.csv\", sep=\";\")\n",
    "\n",
    "p_df1.loc[:, \"timestamp\"] = p_df1[\"timestamp\"] + 1000000\n",
    "p_df0.loc[:, \"timestamp\"] = p_df0[\"timestamp\"] + 2000000\n",
    "p_df = pd.concat([p_df2, p_df1, p_df0])\n",
    "\n",
    "kelp_df = p_df[p_df[\"product\"] == \"KELP\"].copy()\n",
    "si_df = p_df[p_df[\"product\"] == \"SQUID_INK\"].copy()\n",
    "train_arr = kelp_df[\"mid_price\"].to_numpy()\n",
    "kelp_mod = ARIMA(p=5, d=1, q=5)\n",
    "kelp_mod.train(train_arr)\n",
    "\n",
    "'''\n",
    "#replace Nan values with 0 in bid_volume and ask_volume\n",
    "si_df[\"bid_volume_1\"].fillna(0, inplace=True)\n",
    "si_df[\"bid_volume_2\"].fillna(0, inplace=True)\n",
    "si_df[\"bid_volume_3\"].fillna(0, inplace=True)\n",
    "si_df[\"ask_volume_1\"].fillna(0, inplace=True)\n",
    "si_df[\"ask_volume_2\"].fillna(0, inplace=True)\n",
    "si_df[\"ask_volume_3\"].fillna(0, inplace=True)\n",
    "si_df['bid_vol'] = si_df['bid_volume_1'] + si_df['bid_volume_2'] + si_df['bid_volume_3']\n",
    "si_df['ask_vol'] = si_df['ask_volume_1'] + si_df['ask_volume_2'] + si_df['ask_volume_3']\n",
    "\n",
    "volume_scale = 0.3 \n",
    "plt.xlim(0, 100000)\n",
    "plt.scatter(si_df[\"timestamp\"], si_df[\"mid_price\"], s=0.1, c=\"blue\", label=\"SQUID_INK\")\n",
    "plt.xlim(0, 100000)\n",
    "\n",
    "# For each point, add a line for bid_volume (upward)\n",
    "for i, row in si_df.iterrows():\n",
    "    if row['timestamp'] > 100000:\n",
    "        break\n",
    "    plt.vlines(x=row['timestamp'], \n",
    "               ymin=row['mid_price'], \n",
    "               ymax=row['mid_price'] + row['bid_vol'] * volume_scale, \n",
    "               color='green', \n",
    "               linewidth=.5,\n",
    "               alpha=0.7)\n",
    "\n",
    "# For each point, add a line for ask_volume (downward)\n",
    "for i, row in si_df.iterrows():\n",
    "    if row['timestamp'] > 100000:\n",
    "        break\n",
    "    plt.vlines(x=row['timestamp'], \n",
    "               ymin=row['mid_price'] - row['ask_vol'] * volume_scale, \n",
    "               ymax=row['mid_price'], \n",
    "               color='red', \n",
    "               linewidth=.5,\n",
    "               alpha=0.7)\n",
    "\n",
    "si_df.head()\n",
    "'''\n",
    "print(\"ar_params\")\n",
    "print(kelp_mod.ar_params)\n",
    "print(\"ma_params\")\n",
    "print(kelp_mod.ma_params)\n",
    "print(\"mean\")\n",
    "print(kelp_mod.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_df = kelp_df[kelp_df[\"timestamp\"] < 2000000]\n",
    "test_df = kelp_df[kelp_df[\"timestamp\"] >= 2000000]\n",
    "train_df = train_df[\"mid_price\"].to_numpy()\n",
    "test_df = test_df[\"mid_price\"].to_numpy()\n",
    "\n",
    "model = ARIMA(p=5, d=1, q=5) \n",
    "model.train(train_df)\n",
    "\n",
    "slices = []\n",
    "for i in range(3000):\n",
    "    start = np.random.randint(0, len(test_df) - 8)\n",
    "    slices.append(test_df[start:start + 8])\n",
    "e = []\n",
    "for s in slices:\n",
    "    pred = model.predict(s[:6], 2).astype(np.int64)\n",
    "    print(\"Pred: \", pred)\n",
    "    print(\"Truth: \", s[6:].astype(np.int64))\n",
    "    e.append(np.sum(s[6:].astype(np.int64) - pred))\n",
    "avg_e = np.mean(np.abs(e))\n",
    "print(\"Average Error: \", avg_e)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
